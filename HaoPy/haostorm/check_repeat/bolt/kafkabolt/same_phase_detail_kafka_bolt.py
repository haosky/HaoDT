# -*- coding: utf-8 -*-from pyleus.storm import SimpleBoltimport tracebackimport copyimport logging.handlersfrom pyleus.storm import namedtuplefrom haounits.loggerDefTools import get_defTestLoggerfrom haounits.loggerDefTools import get_defFileLogger as getlogfrom haokafka.same_art.phase2kafka import phase2kafkaimport sysreload(sys)sys.setdefaultencoding('utf-8')__author__ = 'hao'log = getlog(fileName="same_phase_detail_kafka_bolt.log",loggerMain='same_phase_detail_kafka_bolt')# log = get_defTestLogger(level=logging.DEBUG)pass_obj = namedtuple("dockafka", "key value")class same_phase_detail_kafka_bolt(SimpleBolt):    OUTPUT_FIELDS = pass_obj    PHASE_TO_DOC_LEN = 4    PHASE_RAW_LEN = 8    '''    ->es_searcch_phase2doc_bolt    比较句子差异，并记录其他业务相关的字段信息    content input should be unicode    '''    def initialize(self):         self.p2ka = phase2kafka()    def process_tuple(self, tup):        try:            data = tup.values            sen_id = data[0]            gets = data[1]            # 原文章标题            project = gets[0]            # 相似句子相关字段信息            sam_detail = gets[1]            id_split = sen_id.split(':')            doc_uuid = id_split[0]            # 插入kafka，队列为docid            self.p2ka.start_same_phase_producer(doc_uuid)            sam_detail.update({'doc_title':project,'doc_sentence_uuid':sen_id})            self.p2ka.producer_same_phase(sam_detail)            self.p2ka.stop_same_phase_producer()            result = (sen_id, gets)            log.info(result)            self.emit(result)            log.info('put sucess')        except Exception as e:            log.error(traceback.format_exc())if __name__ == "__main__":    same_phase_detail_kafka_bolt().run()# # @Test# from haostorm.testSite.SimpleBolt_MN import SimpleBolt# if __name__ == '__main__':#     es_sd = same_phase_detail_kafka_bolt()#     es_sd.initialize()#     class tup :#         values=(u'15994285707331215007fdac42722f20a5463be19e5ac5010c1c:149', [u'\u5173\u4e8e\u5b66\u4e60\u5ba3\u4f20\u548c\u8d2f\u5f7b\u5b9e\u65bd\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u6559\u80b2\u6cd5\u300b\u7684\u901a\u77e5', {'same_doc_title': u'\u5173\u4e8e\u5b66\u4e60\u5ba3\u4f20\u548c\u8d2f\u5f7b\u5b9e\u65bd\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u6559\u80b2\u6cd5\u300b\u7684\u901a\u77e5', 'upload_at': u'\\N', 'wordcount': 2487, 'doc_sentence': u'<span class="sim gray">\u5b66\u4e60\u3001\u5ba3\u4f20\u4e2d\u7684\u6709\u5173\u53cd\u6620\u548c\u95ee\u9898\uff0c\u8bf7\u53ca\u65f6\u62a5\u9001\u56fd\u5bb6\u6559\u59d4</span>', 'doc_sentence_word_count': 24, 'sam_in_phase': '', 'sim_rate_value': 100.0, 'sam_sentence_id': u'15994285707331215007fdac42722f20a5463be19e5ac5010c1b:149', 'doc_sentence_id': u'149', 'submiter': u'\u67d0\u67d0', 'find_sam_sentence': u'<span class="lsim gray">\u5b66\u4e60\u3001\u5ba3\u4f20\u4e2d\u7684\u6709\u5173\u53cd\u6620\u548c\u95ee\u9898\uff0c\u8bf7\u53ca\u65f6\u62a5\u9001\u56fd\u5bb6\u6559\u59d4</span>', 'sim_rate': u'100.0%', 'sam_sentence_word_count': 24}])##     es_sd.process_tuple(tup())